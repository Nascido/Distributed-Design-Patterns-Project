O desenvolvimento da infraestrutura central do Sistema de Cotações em Tempo Real (Trabalho 2) exige a aplicação rigorosa de padrões de projeto distribuídos para mitigar desafios críticos como escalabilidade e alta disponibilidade. A seguir, detalha-se a fundamentação teórica e arquitetural dos padrões propostos, com foco nas primitivas de programação em C, conforme as diretrizes do sistema.

## I. Padrão Circuit Breaker (Disjuntor)

### Fundamentação Teórica

O padrão Circuit Breaker (Disjuntor) é essencial em arquiteturas distribuídas para gerenciar dependências externas instáveis. Sua principal função é impedir que uma falha persistente ou latência excessiva em um serviço externo cause falhas em cascata em todo o sistema, melhorando a disponibilidade e a gestão eficiente de recursos.

**Problema Resolvido (Trabalho 2):** O Circuit Breaker protege o motor de cotações primário da dependência de um serviço externo lento ou falho. Ele impede que recursos críticos do serviço primário fiquem bloqueados à espera de _time-outs_ repetitivos, permitindo que o sistema falhe rapidamente e, potencialmente, utilize uma alternativa (fallback).

### Aplicação e Implementação em C (Conexão e Timeout)

O Circuit Breaker atua no ponto onde o Serviço de Cotações primário tenta se comunicar com o Serviço Externo. A transição de estado (Closed, Open, Half-Open) depende da taxa de sucesso/falha das requisições, que por sua vez, são frequentemente determinadas por falhas de conexão ou _timeouts_.

Na programação de rede em C, a detecção de falha de comunicação ou _timeout_ é crucial.

**Primitivas de Conexão em C (Guia Beej's):** A tentativa de conexão a um servidor utiliza a função `connect()`. Se o servidor externo estiver inoperante ou a rede congestionada, `connect()` pode bloquear ou falhar. O Guia Beej's indica que, se a conexão não puder ser estabelecida imediatamente, `connect()` bloqueará até que um limite de espera (_timeout_) seja atingido, abortando a conexão e retornando um erro.

A lógica do _Circuit Breaker_ é ativada quando detecta falhas ou lentidão, como:

1. **Conexão Recusada:** `ECONNREFUSED`.
2. **Timeout:** `ETIMEDOUT`.

Para evitar o bloqueio da _thread_ do serviço de cotações enquanto espera por uma conexão ruim, pode-se configurar o _socket_ para modo não-bloqueante e usar `select()` ou `poll()` com um _timeout_ customizado, conforme sugerido pelo Guia Beej's para operações de `connect()` com limite de tempo.

**Snippets de Sockets em C (Conceito de Falha/Erro):** O _Circuit Breaker_ monitora o valor de retorno das chamadas de rede e o `errno`.

```c
// Adaptado do Guia Beej's para connect() e erros
int result = connect(sockfd, (struct sockaddr *)address, addrlen);
if (result == -1) {
    if (errno == ETIMEDOUT || errno == ECONNREFUSED) {
        // Falha detectada: Iniciar lógica do Circuit Breaker (transição para OPEN)
        // O Circuit Breaker resolve o problema de recursos críticos ficarem
        // ocupados esperando time-outs repetitivos durante falhas.
        fprintf(stderr, "Erro de conexão/timeout: Circuit Breaker ativado!\n");
        // ... Lógica de fallback ...
    } else {
        perror("Erro de conexão não esperado");
    }
}
```

## II. Padrão Publisher/Subscriber (Pub/Sub)

### Fundamentação Teórica

O padrão Publisher/Subscriber (Publicador/Assinante) é uma solução assíncrona para comunicação e difusão de eventos entre componentes. Ele permite que componentes (Publishers) avisem outros componentes (Subscribers) sobre eventos ou informações, sem a necessidade de conhecer a identidade dos destinatários.

**Componentes Chave:** O sistema é mediado por um _Broker_ (ou _Message Queue_) que gerencia as mensagens, tipicamente associadas a um tópico (ex: "Mudança de Preço"). A comunicação é assíncrona, e as mensagens são frequentemente enfileiradas ou empilhadas no _Broker_.

**Problema Resolvido (Trabalho 2):** Permite que os clientes sejam notificados instantaneamente sobre mudanças de preço (Distribuição de Preços) sem que o serviço de cotação precise gerenciar ou conhecer ativamente cada conexão cliente individualmente, aumentando a escalabilidade e desacoplando os componentes.

### Aplicação e Implementação em C (Multiplexação)

Embora implementações robustas de Pub/Sub utilizem plataformas dedicadas (e.g., Kafka, Rabbit MQ), o módulo Distribuição de Preços, se construído a partir de _sockets_ em C, deve utilizar técnicas de multiplexação de E/S para permitir que o Broker lide com milhares de _Subscribers_ simultaneamente, evitando que o processo fique bloqueado em um único _socket_.

**Multiplexação com `poll()` ou `select()`:** As funções `select()` e `poll()` são cruciais para monitorar múltiplos descritores de arquivo (sockets) de uma vez, esperando que algum esteja pronto para leitura (receber mensagens) ou escrita (enviar mensagens).

O `poll()` é mais eficiente e não possui o limite de 1024 descritores de arquivos presente no `select()`, sendo mais escalável para um Broker.

**Snippets de Sockets em C (Utilização de `poll()` para o Broker):** A função `poll()` monitora um _array_ de estruturas `pollfd`.

```c
#include <poll.h>
#define STDIN 0 // Exemplo: 0, ou descritor do socket principal

// Estrutura para monitorar sockets de múltiplos subscribers/publishers
struct pollfd pfds[MAX_CLIENTS];
int fd_count = 0;
int num_events;

// Adicionando um novo socket (newfd) para monitoramento de leitura (POLLIN)
pfds[fd_count].fd = newfd;
pfds[fd_count].events = POLLIN; // Pronto para ler
fd_count++;

// Espera por eventos por um tempo limite (timeout em milissegundos)
num_events = poll(pfds, fd_count, timeout_ms);

if (num_events > 0) {
    for (int i = 0; i < fd_count; i++) {
        if (pfds[i].revents & POLLIN) {
            // O socket pfds[i].fd está pronto para ler!
            // O broker pode processar a mensagem (publicação ou inscrição)
            // e distribuí-la aos demais subscribers.
        }
    }
}
```

## III. Padrão Particionamento (Sharding)

### Fundamentação Teórica

O Particionamento, ou _Sharding_, é um padrão arquitetural que distribui os dados de um sistema em múltiplos servidores (partições ou _shards_). Isso é necessário quando o volume de dados e o número de requisições excedem a capacidade de um único servidor, gerenciando o custo de armazenamento e a latência de consultas.

**Problema Resolvido (Trabalho 2):** O repositório de dados de histórico de transações está excessivamente grande e lento. O _Sharding_ resolve isso distribuindo a carga de armazenamento e processamento entre múltiplos nós de banco de dados.

**Mecanismos de Distribuição:** A distribuição de dados entre _shards_ pode ser baseada em intervalos (ex: chaves A-M em Shard 1, N-Z em Shard 2) ou por dispersão (ex: usando uma função hash, `Hash(chave) % N_shards`).

### Aplicação e Implementação em C (Comunicação com Shards)

A implementação do Sharding envolve a definição de regras para distribuir os dados e a lógica para encontrar o servidor correto (nó roteador ou cliente que conhece as partições). O acesso a esses _shards_ é feito via comunicação de rede.

**Concorrência (The Art of Concurrency):** Uma vez que os dados são particionados, o sistema pode executar partes do trabalho paralelamente. A decomposição de dados (_data decomposition_) é o método que expressa a concorrência dividindo grandes estruturas de dados (como o histórico de transações) e atribuindo essas porções a diferentes processos/máquinas, o que melhora a escalabilidade.

O cliente ou roteador precisa de primitivas de rede para estabelecer uma conexão com o _shard_ correto, após determinar seu endereço IP e porta.

```c
// Determinar endereço do Shard 1, baseado na regra de particionamento (ex: chaves A-M)
char *shard_ip = "192.168.10.1";
char *shard_port = "4001";
int shard_sockfd;
struct addrinfo hints, *res;

// ... obteraddrinfo() e preencher hints ...

// Criar o socket e conectar ao shard (cliente ou roteador)
shard_sockfd = socket(res->ai_family, res->ai_socktype, res->ai_protocol);
connect(shard_sockfd, res->ai_addr, res->ai_addrlen);

// Enviar a requisição específica para o shard
send(shard_sockfd, request_data, request_len, 0);
```

## IV. Padrão Scatter/Gather

### Fundamentação Teórica

O padrão Scatter/Gather (Dispersar/Coletar) é utilizado em sistemas replicados ou particionados para processar consultas complexas que exigem agregação de dados de múltiplas fontes.

**Funcionamento:** Um nó Raiz (_Root Node_), que pode ser um componente do sistema ou parte do cliente, recebe uma requisição complexa, a distribui (_scatter_) para múltiplas réplicas ou _shards_, coleta (_gather_) as respostas parciais e as combina (_merge_) em uma resposta unificada para o cliente. Partes do trabalho podem ser executadas em paralelo.

**Problema Resolvido (Trabalho 2):** Permite responder a consultas complexas (ex: "preço médio atual" do serviço replicado e "últimas 10 transações históricas" dos _shards_) de forma eficiente, dividindo o trabalho e explorando o paralelismo e a distribuição de dados.

### Aplicação e Implementação em C (Paralelismo e Agregação)

A implementação eficiente do Scatter/Gather na camada de Serviço de Agregação de Consultas exige concorrência ou paralelismo para o envio e espera simultânea das respostas parciais dos _shards_ e réplicas.

Se a implementação for em C, o Root Node (Serviço de Agregação) pode utilizar _threads_ (ex: Pthreads) para executar as chamadas de rede de forma paralela.

**Concorrência com Threads (The Art of Concurrency):**

O design concorrência geralmente começa com um código serial que é transformado para execução paralela. A alocação estática de trabalho, onde a divisão de tarefas é conhecida no início (cada sub-requisição vai para um destino fixo), é o método mais simples e com menor _overhead_ para se tentar primeiro. No Scatter/Gather, a tarefa é enviar e esperar a resposta de um destino específico.

**Fluxo Conceitual do Root Node:**

1. **Scatter (Dispersão):** O nó Root cria um _socket_ e uma _thread_ para cada sub-requisição (e.g., uma thread para consultar a Réplica A, outra para o Shard B).
2. **Gather (Coleta):** O nó Root espera que todas as _threads_ de comunicação concluam suas tarefas (usando `pthread_join`, se Pthreads for usado).
3. **Merge (Fusão):** As respostas parciais são combinadas em uma resposta final.

```c
// Exemplo Conceitual (omitindo tratamento de erros e detalhes de pthreads)
// O Root Node dispara requisições para 2 destinos (Replica e Shard)
// A Réplica 1 (preço atual) e o Shard 1 (dados históricos)

// Pseudocódigo (Baseado na metodologia de threading em C):
void *handle_replica_request(void *arg) {
    // 1. Conectar/Enviar/Receber dados da Réplica 1
    // 2. Armazenar resultado parcial
    return NULL;
}

void *handle_shard_request(void *arg) {
    // 1. Conectar/Enviar/Receber dados do Shard 1
    // 2. Armazenar resultado parcial
    return NULL;
}

void scatter_and_gather() {
    pthread_t thread_replica, thread_shard;

    // SCATTER: Inicia threads para executar requisições em paralelo
    pthread_create(&thread_replica, NULL, handle_replica_request, NULL);
    pthread_create(&thread_shard, NULL, handle_shard_request, NULL);

    // GATHER: Espera a conclusão de ambas as threads
    pthread_join(thread_replica, NULL);
    pthread_join(thread_shard, NULL);

    // MERGE: Combina os resultados parciais e envia resposta final
    printf("Resultados da réplica e do shard coletados e combinados.\n");
}
```

Essa abordagem garante que as consultas de dados sejam feitas concorrentemente, minimizando a latência da resposta complexa. É crucial garantir que as operações de escrita (armazenamento dos resultados parciais) sejam protegidas se as _threads_ compartilharem variáveis (regiões críticas), um conceito central da programação concorrente.

---

A fundamentação arquitetural para o **Trabalho 2** (Sistema de Cotações) reside na adoção de Padrões de Projeto Distribuídos para garantir a escalabilidade, resiliência e disponibilidade do sistema. Conforme solicitado, será fornecida uma explicação detalhada, módulo por módulo, com foco nas primitivas de implementação em C, baseadas no _Guia Beej's_ e na teoria de concorrência.

## I. Padrão Circuit Breaker (Disjuntor)

### 1. Fundamentação Teórica e Propósito

O padrão Circuit Breaker é um padrão de resiliência fundamental em ambientes distribuídos. O principal problema que ele resolve é a ocorrência de falhas em cascata, onde requisições repetitivas a um servidor instável fazem com que os recursos críticos do cliente fiquem ocupados esperando por _timeouts_.

**No contexto do Trabalho 2 (Serviço de Cotações em Tempo Real):** O Circuit Breaker é aplicado para proteger o motor de cotações primário contra falhas ou lentidão do Serviço Externo dependente. Ao ser ativado, ele melhora a disponibilidade e a gestão eficiente de recursos do serviço principal.

### 2. Estados Operacionais

O disjuntor opera em três estados distintos:

1. **Closed (Fechado):** É o estado padrão, onde as requisições para o serviço remoto são permitidas. Se o número de falhas alcançar um limite pré-definido (_threshold_), o disjuntor transiciona para o estado Open.
2. **Open (Aberto):** O disjuntor interrompe imediatamente todas as chamadas para o serviço dependente, retornando um erro rápido (fail-fast) ou utilizando um _fallback_. Isso impede o desperdício de recursos críticos (como _threads_ ou memória). Um _reset timeout_ é iniciado.
3. **Half-Open (Semi-Aberto):** Após o _reset timeout_ expirar, o disjuntor transiciona para este estado, permitindo que uma requisição de teste passe para o serviço remoto. Se a requisição for bem-sucedida, ele volta para Closed; se falhar, retorna para Open.

### 3. Implementação em C: Detecção de Falha (Trigger)

A transição para o estado **Open** é disparada pela detecção de falhas de comunicação, tipicamente falhas de conexão ou _timeouts_.

Na programação de rede em C, a chamada `connect()` é usada para tentar ativamente estabelecer uma conexão com o servidor remoto. Se o servidor estiver indisponível, `connect()` pode bloquear ou falhar.

A chamada `connect()` falhará e retornará -1 se não puder ser estabelecida imediatamente, bloqueando por um período (timeout) até que a conexão seja abortada.

Para que o Serviço de Cotações evite que suas _threads_ bloqueiem indefinidamente ou por longos períodos à espera de um serviço externo lento, é crucial configurar o _socket_ para operação não-bloqueante e usar multiplexação com _timeout_.

**Aplicação de Chamadas de Sistema em C para Non-Blocking Connect (Conceitual):** Para implementar a falha rápida (fast-fail), o cliente pode usar `fcntl()` para configurar o socket como não-bloqueante (`O_NONBLOCK`):

```c
#include <fcntl.h>
#include <unistd.h>
#include <errno.h>

// Função para configurar um socket para modo non-blocking
void set_nonblocking(int sockfd) {
    // Obter flags atuais
    int flags = fcntl(sockfd, F_GETFL, 0); //
    if (flags == -1) {
        perror("fcntl F_GETFL");
        // Lógica de falha
    }
    // Configurar flag O_NONBLOCK
    if (fcntl(sockfd, F_SETFL, flags | O_NONBLOCK) == -1) {
        perror("fcntl F_SETFL");
        // Lógica de falha
    }
}

// Lógica de conexão (para testar o disjuntor)
int attempt_connection(int sockfd, const struct sockaddr *addr, size_t addrlen) {
    // O disjuntor deve estar no estado CLOSED antes desta chamada

    // 1. Tenta conectar: em modo non-blocking, isso retorna imediatamente
    int result = connect(sockfd, addr, addrlen); //

    // 2. Se connect() falhar imediatamente:
    if (result == -1) {
        // Se errno for EINPROGRESS, a conexão está em andamento (esperado para non-blocking)
        if (errno == EINPROGRESS) {
            // A conexão está em andamento. Usar select() ou poll() com um timeout curto
            // para aguardar a conclusão.

            // Se o timeout expirar ou a conexão falhar (ECONNREFUSED/ETIMEDOUT),
            // a falha é detectada: Disjuntor -> OPEN.

            // Exemplo conceitual usando select/poll para timeout:
            // if (wait_for_connection_with_timeout(sockfd, 500ms) == TIMEOUT_FAILURE) {
            //      return CIRCUIT_BREAKER_OPEN_FAILURE;
            // }
            return 0; // Conexão bem-sucedida após esperar
        }

        // Se retornar ECONNREFUSED (serviço externo morto) ou ETIMEDOUT (timeout imediato)
        // a falha é detectada. Disjuntor -> OPEN.
        // O Circuit Breaker evita que o cliente repita essa tentativa continuamente.
        return -1; // Falha de Conexão - ATIVA O DISJUNTOR
    }
    // Conexão imediata bem-sucedida (raro em WAN)
    return 0;
}
```

---

## II. Padrão Publisher/Subscriber (Pub/Sub)

### 1. Fundamentação Teórica e Propósito

O padrão Pub/Sub é crucial para arquiteturas orientadas a eventos. Ele resolve o desafio de componentes do sistema precisarem avisar outros sobre eventos (como mudanças de preço) sem a necessidade de o Publicador conhecer a identidade ou o número de Assinantes. A comunicação é fundamentalmente assíncrona.

**No contexto do Trabalho 2 (Distribuição de Preços):** O módulo Distribuição de Preços deve utilizar o Pub/Sub, mediado por um _Broker_, para gerenciar e difundir eventos de novas cotações (mensagens com um tópico) de forma assíncrona. Isso atende ao requisito de notificar clientes instantaneamente sem gerenciar ativamente cada conexão.

### 2. Componentes e Fluxo

- **Publisher:** Um nó que publica uma mensagem. O Serviço de Cotação primário, ao atualizar um preço, torna-se um Publisher.
- **Broker:** Gerencia as mensagens e é o ponto central de intermediação. As mensagens são associadas a um tópico (e.g., "MUDANÇA_DE_PREÇO") e são tipicamente enfileiradas ou empilhadas.
- **Subscriber:** Um nó que assina um tópico de interesse. Os clientes front-end são os Subscribers que esperam cotações.

### 3. Implementação em C: Escalabilidade do Broker via Multiplexação

Para que o _Broker_ (módulo de Distribuição de Preços) consiga lidar com o grande volume de _Subscribers_ (clientes) que o sistema exige, ele não pode utilizar o modelo tradicional de bloqueio (_blocking_) em um único _socket_.

É necessário usar a **Multiplexação Síncrona de E/S** (I/O Multiplexing), que permite ao servidor monitorar múltiplos descritores de arquivo (sockets) de forma eficiente, esperando que algum esteja pronto para leitura ou escrita.

#### Comparação entre `select()` e `poll()`:

Tanto `select()` quanto `poll()` são utilizadas para monitorar a prontidão dos sockets.

- `select()`: Utiliza a estrutura `fd_set`, que possui um limite fixo, geralmente 1024 descritores de arquivos, sendo menos escalável para centenas de conexões.
- `poll()`: É mais eficiente ao monitorar diversos descritores de arquivos e não possui o limite de 1024 descritores de arquivos. É a abordagem recomendada para aplicações que escalam para centenas de conexões.

**Aplicação de Chamadas de Sistema em C (`poll()`):** O _Broker_ deve manter um _array_ de estruturas `struct pollfd` para monitorar todos os sockets dos _Subscribers_ ativos.

```c
#include <poll.h>
#include <stdio.h>

// Estrutura pollfd definida no sistema
struct pollfd {
    int fd;         // O descritor de socket
    short events;   // Bitmap de eventos nos quais estamos interessados
    short revents;  // Bitmap de eventos que ocorreram
};

// Exemplo conceitual de monitoramento de clientes (Subscribers)
void broker_event_loop(struct pollfd *pfds, int fd_count) {
    // Timeout negativo para esperar indefinidamente até um evento ocorrer
    int poll_count = poll(pfds, fd_count, -1);

    if (poll_count == -1) {
        perror("poll");
        return;
    }

    // Percorrer a lista de descritores
    for (int i = 0; i < fd_count; i++) {
        // Verificar se o socket está pronto para leitura (POLLIN)
        if (pfds[i].revents & POLLIN) {
            int subscriber_fd = pfds[i].fd;

            // Se for o socket do Broker (listener), aceitar nova inscrição (accept())
            // Caso contrário, ler dados (recv()) do Subscriber

            // Lógica de Distribuição (Broadcast de Preço):
            // O Broker deve usar send() para enviar (POLLOUT) os dados da nova cotação
            // para todos os outros Subscribers na lista.
        }
    }
}
// O Macro POLLIN avisa quando dados estão prontos para recv() no socket.
```

---

## III. Padrão Particionamento (Sharding)

### 1. Fundamentação Teórica e Propósito

O Particionamento, ou _Sharding_, é um padrão que trata o desafio de gerenciamento de dados maciços. Ele é necessário quando o banco de dados de histórico de transações está excessivamente grande e lento, e a quantidade de requisições de consulta excede a capacidade de um único servidor. O _Sharding_ distribui os dados por múltiplos servidores (_shards_) para gerenciar o custo de armazenamento e a latência de consultas.

**No contexto do Trabalho 2 (Repositório de Dados Históricos):** O _Sharding_ é aplicado para distribuir o histórico de transações, permitindo que as consultas sejam distribuídas e processadas em paralelo.

### 2. Estratégias de Distribuição e Concorrência

A distribuição dos dados entre os _shards_ deve seguir regras bem definidas:

1. **Intervalos:** Onde as chaves são mapeadas para _shards_ baseadas em faixas de valores (ex: A-M para Shard 1, N-Z para Shard 2).
2. **Dispersão:** Utiliza-se uma função hash sobre a chave, e o resultado modulo o número de _shards_ determina o destino.

Em termos de concorrência, o _Sharding_ é uma aplicação da **Decomposição de Dados** (_Data Decomposition_), onde a concorrência é alcançada dividindo grandes estruturas de dados em pedaços e atribuindo essas porções a diferentes processos/máquinas para serem processadas.

### 3. Implementação em C: Roteamento para o Shard Correto

O cliente ou um nó roteador deve determinar qual _shard_ possui o dado solicitado e iniciar uma comunicação de rede TCP/IP com ele.

1. **Endereçamento:** O cliente precisa do endereço IP (Camada de Rede) e do número da porta (Camada de Transporte) do _shard_ de destino. O IPv4 utiliza 32 bits para representar um endereço, geralmente escrito como quatro octetos separados por pontos (ex: 192.168.1.34).
2. **Conexão:** A conexão é feita via `connect()`.

**Aplicação de Chamadas de Sistema em C (Roteamento e Conexão):**

```c
// Pseudocódigo: Determinar e conectar ao Shard
void connect_to_shard(const char *key, int num_shards) {
    // 1. Lógica de Roteamento (Dispersão/Hash)
    unsigned int hash_value = calculate_hash(key);
    int shard_index = hash_value % num_shards;

    // 2. Determinar o endereço do shard (necessita de um mapa estático ou serviço de descoberta)
    char shard_ip[INET6_ADDRSTRLEN];
    char shard_port; // Porta de 16 bits

    // ... (Lógica para obter IP e Porta específicos do shard_index) ...
    // Ex: get_shard_address(shard_index, shard_ip, shard_port);

    struct addrinfo hints, *res;
    // ... preencher hints (AF_INET ou AF_INET6) ...

    // Obter estruturas de endereço (incluindo IP e porta) para o shard
    getaddrinfo(shard_ip, shard_port, &hints, &res);

    // 3. Criar socket e conectar
    int sockfd = socket(res->ai_family, res->ai_socktype, res->ai_protocol);

    // Tenta ativamente estabelecer uma conexão
    if (connect(sockfd, res->ai_addr, res->ai_addrlen) == -1) {
        perror("connect");
        // Lógica de fallback ou retry (potencialmente usando Circuit Breaker)
        return;
    }

    // 4. Enviar a requisição para o shard correto
    send(sockfd, "GET_HISTORY_DATA...", len, 0);

    // ... recv() data ...
    close(sockfd); // Fechar a conexão
}
```

---

## IV. Padrão Scatter/Gather

### 1. Fundamentação Teórica e Propósito

O padrão Scatter/Gather (Dispersar/Coletar) é tipicamente aplicado em sistemas replicados ou particionados (_sharded_). Seu objetivo é dividir uma requisição complexa em partes que podem ser executadas paralelamente em diferentes servidores, minimizando a latência total da resposta através da fusão dos resultados parciais.

**No contexto do Trabalho 2 (Serviço de Agregação de Consultas):** O módulo atua como o **Nó Raiz** (_Root Node_), responsável por atender a consultas complexas que exigem dados em tempo real (réplicas) e dados históricos (shards), combinando-os em uma única resposta.

### 2. Fluxo e Paralelismo

O fluxo do Scatter/Gather envolve três etapas gerenciadas pelo Nó Raiz:

1. **Scatter (Dispersão):** O Nó Raiz recebe a requisição e a distribui para os _shards_ e/ou réplicas.
2. **Gather (Coleta):** O Nó Raiz coleta as respostas parciais dos destinos.
3. **Merge (Fusão):** As respostas parciais (e.g., preço médio atual + últimas 10 transações) são combinadas em uma resposta unificada para o cliente.

Para maximizar o desempenho (eficiência) no _Gather_, é crucial que a distribuição (_scatter_) e o processamento parcial sejam executados em paralelo.

### 3. Implementação em C: Concorrência (Threads) e Comunicação

A concorrência no Nó Raiz (Serviço de Agregação) pode ser implementada em C utilizando _threads_ (ex: Pthreads) para paralelizar as chamadas de comunicação de rede para cada réplica ou _shard_.

A estratégia mais simples e eficiente para dividir o trabalho quando as tarefas são conhecidas de antemão (consultar Shard A, Réplica B, etc.) é a **Alocação Estática** (_Static Allocation_). Cada _thread_ recebe a tarefa de consultar um nó de destino específico.

**Aplicação de Chamadas de Sistema em C (Simulação de Paralelismo):** O _Root Node_ utiliza `pthread_create` para iniciar a comunicação paralela e `pthread_join` para esperar pela conclusão de todas as sub-requisições (Gather).

```c
#include <pthread.h>
#include <sys/socket.h>
#include <stdio.h>

// Estruturas compartilhadas para coletar resultados parciais (requerem sincronização)
typedef struct {
    char data;
    int status;
} PartialResult;

PartialResult price_result;
PartialResult history_result;

// Função executada por uma thread para consultar um nó (replica ou shard)
void *query_node(void *ip_address) {
    // 1. Conectar ao nó usando socket() e connect()
    int sockfd = setup_connection((char *)ip_address);

    // 2. Enviar requisição específica
    send(sockfd, "GET_DATA_REQUEST", 16, 0);

    // 3. Receber resposta (recv())
    // ... recv(sockfd, response_buffer, size, 0) ...

    // Para simplificar, armazenamos o resultado na estrutura global:
    if (strcmp((char *)ip_address, "REPLICA_IP") == 0) {
        strcpy(price_result.data, "Preço Médio: 100.00");
    } else {
        strcpy(history_result.data, "Últimas 10 Transações: [...]");
    }

    // Fechar conexão
    close(sockfd);
    return NULL;
}

void scatter_and_gather_complex_query() {
    pthread_t thread1, thread2;

    // SCATTER: Dispersar requisições em paralelo
    char *replica_ip = "REPLICA_IP";
    char *shard_ip = "SHARD_IP";

    pthread_create(&thread1, NULL, query_node, (void *)replica_ip);
    pthread_create(&thread2, NULL, query_node, (void *)shard_ip);

    // GATHER: Esperar que ambas as threads de comunicação terminem
    pthread_join(thread1, NULL);
    pthread_join(thread2, NULL);

    // MERGE: Combinar os resultados parciais em uma única resposta
    printf("Consulta Completa: %s | %s\n", price_result.data, history_result.data);
}
```

_Nota: Se as threads no `query_node` acessassem e modificassem dados globais de forma concorrente, seria necessário adicionar exclusão mútua (locks/mutexes) para proteger regiões críticas, um princípio essencial da concorrência._